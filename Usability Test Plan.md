# Testing Overview
The following test plan describes the objectives of our testing of our working prototype created in Part One of the Project. This involved the creation of a Flat Expenses Management App.

Our key objectives from User testing are to evaluate the following:
* Handling of **“Core Functionalities”** offered by the working prototype. This includes Creation of expenses, paying relevant users, viewing past/future expenses, managing insights and modifying settings. We will primarily be observing the usability of our app for the test subjects
* Identify any **bugs** or **pain points** in the design experienced by users.
* Understand the overall **emotional feeling** as users use our app. As we are handling something as delicate as finances. We want to ensure that users are confident in their decisions to reduce stress on them. (THIS IS OPTIONAL)
* Collect **general feedback** and **satisfaction** from test subjects.

With these objectives in mind, we will collect and analyse user experience of the app through the use metrics. From these metrics, we will then classify them by severity, giving us and understanding of how will prioritise changes in future iterations.
This study will be primarily focused on the experience of University Students. They will be 6 SWEN303 Students at Victoria University. While it is good that we are doing User testing, this does not cover the needs for all our intended userbase. Future testing must be done for a broader picture on the usability of our application.


# Methodology
## Participants
#### Selection Criteria
Participants for this usability test are software engineering students from Victoria University enrolled in the SWEN303 course. These participants were selected through group pairings suggested by the course lecturer. The participants' average skill level with software systems is assumed to be relatively high, given their background, which may influence their interaction with the prototype. This selection aims to ensure that participants can complete the set tasks effectively, though their advanced skill level should be considered when analyzing test results.

#### Participant Details
- **Number of Participants**: Six
- **Background**: Software engineering students with experience in using and evaluating software systems
- **Skill Level**: Relatively high, given their academic background and familiarity with technology

### Environment
Tests will be conducted remotely, with participants located in a quiet environment, ideally at their workstation or desk. This setup aims to minimize distractions and simulate a typical user environment. The test facilitator and note taker will join the participants in a voice call, and the participants will access the system prototype via a Figma link, which can be opened in a web browser without additional software installation.

### Procedure

Test participants will be asked to complete testing in a quiet environment, preferably at their workstation or desk. The test facilitator and note taker will then join a participant in a voice call, and the participant will be sent the system prototype through a Figma link which they can open in a browser without downloading additional software.

The test facilitator will then introduce the system to the participant and their role in testing. To ensure honest answers are obtained from the participant, it is important to ensure them that it is the system being evaluated, not their proficiency. Additionally, the facilitator will inform the user that personal information such as their name will not be used outside of identifying them for the testing procedure and analysis. The facilitator will then give a quick overview of the purpose and function of the system with reference to the prototype.

The facilitator will then ask test participants to read aloud each task before completing it, voicing their thought process as they do so. After each task, the facilitator will ask the participant for their general thoughts on the process. Another person present in the call will be the note taker who will record notes on the participant's response to each task, as well as their thoughts during completion. Notes on time taken, any potential errors in the system, and differences in expectation by the user and the actual system will be recorded also. 

After all tasks are completed, the users will be asked to complete a Google form questionnaire independently. This questionnaire will ask users to evaluate system function through the performance of each task and overall, as well as questions on general function and their interaction with it.


# Script
#### Introduction and Consent
1. **Welcome and Briefing**: 
   - The facilitator will welcome the participants and provide a brief overview of the test's purpose, emphasizing that the focus is on evaluating the system, not the participants.
   - Participants will be assured that their personal information will remain confidential and only used for identifying them during the testing process.

2. **Consent Form**: 
   - Participants will be asked to read and sign a consent form, which outlines their role in the test, the nature of the tasks, and their rights as participants.

#### Testing of Prototypes
1. **Working with the Prototype**:
   - Participants will then go through the task list for our prototype. They will be accompanied by a facilitator/note-taker who will help direct them through the various tasks and record information. We will be recording the user to later conduct sentiment analysis on the users.
   - Key findings will focus on points of confusion while navigating the application.

2. **Collecting Quantitative Data**:
   - Users will then be asked to fill out a survey consisting of SUS questions. This will be collected in a google form for later evaluation.

#### Focus Group Evaluation
1. **Splitting Groups**:
   - Participants will be split into two groups of three, we will then use that to conduct a focus group consisting of five questions. 
   - Key goals from this consist of trying to understand emotional feelings and undertones as they navigate the app, as well as future recomendations.    


# Roles


# Tasks


# Focus Group Questions


# Metrics


# Usability Goals


# Problem Severity


